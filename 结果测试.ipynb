{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/home/liyongbo/.local/share/geoist'\n",
      "[Errno 17] File exists: '/home/liyongbo/.local/share/geoist/examples'\n",
      "[Errno 17] File exists: '/home/liyongbo/.local/share/geoist/temp'\n",
      "[Errno 17] File exists: '/home/liyongbo/.local/share/geoist/data'\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import argparse\n",
    "from fileinput import filename\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import rcParams\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import cm\n",
    "import datagen\n",
    "import train\n",
    "import utils\n",
    "from pyevtk.hl import imageToVTK,gridToVTK\n",
    "import datagen\n",
    "import encoder\n",
    "import decoder\n",
    "import discriminator\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import IterableDataset,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_args():\n",
    "    parser = argparse.ArgumentParser(description='gangravity')\n",
    "    parser.add_argument('-c', '--checkpoint', default='./models/checkpoint.pt',\n",
    "                        type=str, help='checkpoint file')\n",
    "    parser.add_argument('-d', '--device', default='cuda:0', type=str, help='computing device')\n",
    "    parser.add_argument('-l', '--gp', default=10, type=int, help='gradient penalty')\n",
    "    parser.add_argument('-g', '--n_gp', default=1, type=int)\n",
    "    parser.add_argument('-b', '--batch_size', default=1, type=int)\n",
    "    parser.add_argument('-n', '--n_batch', default=150, type=int)\n",
    "    parser.add_argument('-e', '--epochs', default=100, type=int)\n",
    "    parser.add_argument('-w', '--world_size', default=3, type=int)\n",
    "    parser.add_argument('--use_spectral_norm', default=False)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def load_models(rank,args,checkpoint=None):\n",
    "    netDec = decoder.GravDecoder()\n",
    "    netDis = discriminator.GravDiscriminator()\n",
    "    netEnc = encoder.GravEncoder()\n",
    "    netEnc = DDP(netEnc.to(rank),device_ids=[rank])\n",
    "    #netDec = DDP(netDec.to(rank),device_ids=[rank])\n",
    "    netDec = netDec.to(rank)\n",
    "    netDis = DDP(netDis.to(rank),device_ids=[rank])\n",
    "    if checkpoint:\n",
    "        netEnc.load_state_dict(checkpoint['enc_state_dict'])\n",
    "        netDis.load_state_dict(checkpoint['dis_state_dict'])\n",
    "#    netEnc = torch.nn.DataParallel(netEnc)\n",
    "#    netDec = torch.nn.DataParallel(netDec)\n",
    "#    netDis = torch.nn.DataParallel(netDis) \n",
    "    print (netDec, netDis, netEnc)\n",
    "    return (netDec, netDis, netEnc)\n",
    "    \n",
    "def dice(pred, target):\n",
    "    smooth = 1\n",
    "    num = pred.size(0)\n",
    "    m1 = pred.view(num, -1)  \n",
    "    m2 = target.view(num, -1)  \n",
    "    intersection = m1 * m2\n",
    "    loss = (2. * intersection.sum(1) + smooth) / ((m1*m1).sum(1) + (m2*m2).sum(1) + smooth)\n",
    "    return loss.sum()/num\n",
    "def my_loss(pre_y, tru_y): \n",
    "    loss = 1 - dice(pre_y, tru_y)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-c CHECKPOINT] [-d DEVICE] [-l GP]\n",
      "                             [-g N_GP] [-b BATCH_SIZE] [-n N_BATCH]\n",
      "                             [-e EPOCHS] [-w WORLD_SIZE]\n",
      "                             [--use_spectral_norm USE_SPECTRAL_NORM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9023 --control=9021 --hb=9020 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"70f29743-6490-4fcc-ad02-fe7acd4f8adc\" --shell=9022 --transport=\"tcp\" --iopub=9024 --f=/home/liyongbo/.local/share/jupyter/runtime/kernel-18728X76L8RpacAHR.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liyongbo/anaconda3/envs/pytorch/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    args_gen = load_args()\n",
    "    checkpoint = torch.load(args_gen.checkpoint)\n",
    "    saved_model = ['enc_state_dict','dis_state_dict']\n",
    "    for model_key in saved_model:\n",
    "        new_keys = list(map(lambda x:x[7:],checkpoint[model_key].keys()))\n",
    "        checkpoint[model_key] = dict(zip(new_keys,list(checkpoint[model_key].values())))\n",
    "    netDec,netDis,netEnc = train.load_models(args_gen,checkpoint,nzyx=nzyx)\n",
    "    netDec.eval()\n",
    "    netDis.eval()\n",
    "    netEnc.eval()\n",
    "    train_length = 10\n",
    "    tes_loss  = 0\n",
    "    tes_metrix = 0\n",
    "    for index_train in  range(train_length):\n",
    "        index_train = index_train*10 +1\n",
    "        with torch.no_grad():\n",
    "\n",
    "            modeltest = 'model{}.npy'.format(str(index_train))\n",
    "            testfile = os.path.join(os.getcwd(), 'traindatasets', \"models\", modeltest)\n",
    "            data = np.load(testfile)\n",
    "            input_data = data[0:2, : , : ]\n",
    "            oue_put = data[2, : , : ]\n",
    "            \n",
    "            input_data = torch.from_numpy(input_data)\n",
    "            input_data = input_data.unsqueeze(0)\n",
    "\n",
    "            density_rec = netEnc(input_data)\n",
    "            rec = np.array(density_rec.sequeeze(0))\n",
    "            plt.figure(figsize=(12, 4), dpi = 150)\n",
    "            ax1 = plt.subplot(131)\n",
    "            plt.imshow(input_data[0,:,:], origin='lower')\n",
    "            ax2 = plt.subplot(132)\n",
    "            plt.imshow(rec, origin='lower')\n",
    "            ax2 = plt.subplot(133)\n",
    "            plt.imshow(input_data[0,:,:]-rec, origin='lower')\n",
    "            plt.savefig(\"{}.png\".format(index_train))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch_old')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f88ada4a5ef58f5823e441d145ac0f0f44b4576abd515d6e5978273197717772"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
